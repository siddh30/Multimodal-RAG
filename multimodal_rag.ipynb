{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "############## Vector Stores ################\n",
    "import uuid\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "\n",
    "############## Summaries ####################\n",
    "import openai\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "\n",
    "############ RAG PIPELINE ###########\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from base64 import b64decode\n",
    "\n",
    "\n",
    "######### PODCAST ############\n",
    "from podcastfy.client import generate_podcast\n",
    "\n",
    "\n",
    "\n",
    "###### AUDIO DISPLAY ##############\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "############ Keys ##########\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 : Partition PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/multimodal-rag-podcast/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "pdf_path = \"./data/pdfs/\"\n",
    "file_path = pdf_path + \"attention.pdf\"\n",
    "\n",
    "# Reference: https://docs.unstructured.io/open-source/core-functionality/chunking\n",
    "chunks = partition_pdf(\n",
    "    filename=file_path,\n",
    "    infer_table_structure=True,            # extract tables\n",
    "    strategy=\"hi_res\",                     # mandatory to infer tables\n",
    "\n",
    "    extract_image_block_types=[\"Image\"],   # Add 'Table' to list to extract image of tables\n",
    "    # image_output_dir_path=output_path,   # if None, images and tables will saved in base64\n",
    "\n",
    "    extract_image_block_to_payload=True,   # if true, will extract base64 for API usage\n",
    "\n",
    "    chunking_strategy=\"by_title\",          # or 'basic'\n",
    "    max_characters=10000,                  # defaults to 500\n",
    "    combine_text_under_n_chars=2000,       # defaults to 0\n",
    "    new_after_n_chars=6000,\n",
    "\n",
    "    # extract_images_in_pdf=True,          # deprecated\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 : Extracting Text, Tables and Images from : Partition PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "\n",
      "2023\n",
      "\n",
      "2\n",
      "\n",
      "0\n",
      "\n",
      "2\n",
      "\n",
      "g u A 2 ] L C . s c [ 7 v 2 6 7 3 0 . 6 0\n",
      "\n",
      "7\n",
      "\n",
      "1\n",
      "\n",
      ":\n",
      "\n",
      "v\n",
      "\n",
      "arXiv\n",
      "\n",
      "i\n",
      "\n",
      "X\n",
      "\n",
      "r\n",
      "\n",
      "a\n",
      "\n",
      "Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works.\n",
      "\n",
      "Attention Is All You Need\n",
      "\n",
      "Ashish Vaswani∗\n",
      "\n",
      "Google Brain\n",
      "\n",
      "avaswani@google.com\n",
      "\n",
      "Noam Shazeer∗ Google Brain noam@google.com\n",
      "\n",
      "Niki Parmar∗ Google Research nikip@google.com\n",
      "\n",
      "Jakob Uszkoreit∗\n",
      "\n",
      "Google Research usz@google.com\n",
      "\n",
      "Llion Jones∗\n",
      "\n",
      "Google Research llion@google.com\n",
      "\n",
      "Aidan N. Gomez∗ † University of Toronto aidan@cs.toronto.edu\n",
      "\n",
      "Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com\n",
      "\n",
      "Illia Polosukhin∗ ‡\n",
      "\n",
      "illia.polosukhin@gmail.com\n",
      "\n",
      "Abstract\n",
      "\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
      "\n",
      "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.\n",
      "\n",
      "†Work performed while at Google Brain.\n",
      "\n",
      "‡Work performed while at Google Research.\n",
      "\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n"
     ]
    }
   ],
   "source": [
    "# Get the images from the CompositeElement object\n",
    "texts=chunks\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Title at 0x3224f5460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3224f55e0>,\n",
       " <unstructured.documents.elements.Formula at 0x3224f5760>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3224f58b0>,\n",
       " <unstructured.documents.elements.Title at 0x3224f5a30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3224f5bb0>,\n",
       " <unstructured.documents.elements.Footer at 0x3224f5d30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3224d7680>,\n",
       " <unstructured.documents.elements.Table at 0x3224f4cb0>,\n",
       " <unstructured.documents.elements.Title at 0x3224f48f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3224f50a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3224f54c0>,\n",
       " <unstructured.documents.elements.Formula at 0x3224f5850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3224f5e20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3224f5f10>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[5].metadata.orig_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Table at 0x3224f4cb0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in texts[5].metadata.orig_elements if 'Table' in str(type(i))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the images from the CompositeElement objects\n",
    "def get_tables(chunks):\n",
    "    tables_dict = {}\n",
    "    tables_html_dict={}\n",
    "    count=0\n",
    "    for chunk in chunks: \n",
    "        elements = chunk.metadata.orig_elements\n",
    "        for el in elements:\n",
    "            if 'Table' in str(type(el)):\n",
    "                chunk_tables = [el for el in elements if 'Table' in str(type(el))]\n",
    "                chunk_tables_html = [el.metadata.text_as_html for el in elements if 'Table' in str(type(el))]\n",
    "                tables_dict[count] = chunk_tables\n",
    "                tables_html_dict[count] = chunk_tables_html\n",
    "        count+=1\n",
    "            \n",
    "    return tables_dict, tables_html_dict\n",
    "\n",
    "\n",
    "tables, tables_html = get_tables(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: ['<table><thead><tr><th>Layer Type</th><th>Complexity per Layer</th><th>Sequential Operations</th><th>Maximum Path Length</th></tr></thead><tbody><tr><td>Self-Attention</td><td>O(n? - d)</td><td>O(1)</td><td>O(1)</td></tr><tr><td>Recurrent</td><td>O(n- d?)</td><td>O(n)</td><td>O(n)</td></tr><tr><td>Convolutional</td><td>O(k-n-d?)</td><td>O(1)</td><td>O(logy(n))</td></tr><tr><td>Self-Attention (restricted)</td><td>O(r-n-d)</td><td>ol)</td><td>O(n/r)</td></tr></tbody></table>'],\n",
       " 7: ['<table><thead><tr><th>Model</th><th>EN-DE</th><th>BLEU EN-FR</th><th>Training EN-DE</th><th>Cost (FLOPs) EN-FR</th></tr></thead><tbody><tr><td colspan=\"5\">ByteNet [18] 23.75</td></tr><tr><td>Deep-Att + PosUnk</td><td></td><td>39.2</td><td></td><td>1.0 - 107°</td></tr><tr><td>GNMT + RL 8]</td><td>24.6</td><td>39.92</td><td>2.3-10!9</td><td>1.4-1070</td></tr><tr><td>ConvS28S [9]</td><td>25.16</td><td>40.46</td><td>9.6-10\\'%</td><td>1.5-1070</td></tr><tr><td>MoE</td><td>26.03</td><td>40.56</td><td>2.0-10\\'9</td><td>1.2. 1079</td></tr><tr><td>Deep-Att + PosUnk Ensemble</td><td></td><td>40.4</td><td></td><td>8.0 - 107°</td></tr><tr><td>GNMT + RL Ensemble (33</td><td>26.30</td><td>41.16</td><td>1.8-1079</td><td>1.1- 1074</td></tr><tr><td>ConvS2S Ensemble [9]</td><td>26.36</td><td>41.29</td><td>7.7-10\\'9</td><td>1.2.10?!</td></tr><tr><td>Transformer (base model)</td><td>27.3</td><td>38.1</td><td>3.3-</td><td>1018</td></tr><tr><td>Transformer (big)</td><td>28.4</td><td>41.8</td><td>2.3.</td><td>1019</td></tr></tbody></table>'],\n",
       " 8: ['<table><thead><tr><th></th><th>N</th><th>dyoast</th><th>de</th><th>Rh</th><th>de</th><th>dy</th><th>Parop</th><th>ets</th><th>Game</th><th>| deny</th><th></th><th>dev).</th></tr></thead><tbody><tr><td>base</td><td>| 6</td><td>512</td><td>2048</td><td>8</td><td>64</td><td>64</td><td>0.1</td><td>O01</td><td>100K</td><td>| 4.92</td><td>25.8</td><td>65</td></tr><tr><td rowspan=\"4\">(A)</td><td></td><td></td><td></td><td>1</td><td>512</td><td>512</td><td></td><td></td><td></td><td>5.29</td><td>24.9</td><td></td></tr><tr><td></td><td></td><td></td><td>4</td><td>128</td><td>128</td><td></td><td></td><td></td><td>5.00</td><td>25.5</td><td></td></tr><tr><td></td><td></td><td></td><td>16</td><td>32</td><td>32</td><td></td><td></td><td></td><td>491</td><td>25.8</td><td></td></tr><tr><td></td><td></td><td></td><td>32</td><td>16 =</td><td>16</td><td></td><td></td><td></td><td>5.01</td><td>25.4</td><td></td></tr><tr><td rowspan=\"2\">(B)</td><td></td><td></td><td></td><td></td><td>16</td><td></td><td></td><td></td><td></td><td>5.16</td><td>9 25.1</td><td>58</td></tr><tr><td></td><td></td><td></td><td></td><td>32</td><td></td><td></td><td></td><td></td><td>5.01</td><td>25.4</td><td>60</td></tr><tr><td rowspan=\"7\">(C)</td><td>2</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>6.11</td><td>23.7</td><td>36</td></tr><tr><td>4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>5.19</td><td>25.3</td><td>50</td></tr><tr><td>8</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>4.88</td><td>25.5</td><td>80</td></tr><tr><td></td><td>256</td><td></td><td></td><td>3232</td><td></td><td></td><td></td><td></td><td>5.75</td><td>24.5</td><td>28</td></tr><tr><td></td><td>1024</td><td></td><td></td><td>128</td><td>128</td><td></td><td></td><td></td><td>4.66</td><td>26.0</td><td>168</td></tr><tr><td></td><td></td><td>1024</td><td></td><td></td><td></td><td></td><td></td><td></td><td>5.12</td><td>25.4</td><td>53</td></tr><tr><td></td><td></td><td>4096</td><td></td><td></td><td></td><td></td><td></td><td></td><td>4.75</td><td>26.2</td><td>90</td></tr><tr><td rowspan=\"4\">()</td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.0</td><td></td><td></td><td>5.77</td><td>24.6</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>0.2</td><td></td><td></td><td>4.95</td><td>25.5</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.0</td><td></td><td>467</td><td>25.3</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.2</td><td></td><td>5.47</td><td>25.7</td><td></td></tr><tr><td>(E)</td><td></td><td></td><td>positional</td><td>embedding</td><td></td><td>instead of</td><td>sinusoids</td><td></td><td></td><td>4.92</td><td>25.7</td><td></td></tr><tr><td>big</td><td>| 6</td><td>1024</td><td>4096</td><td>16</td><td></td><td></td><td>0.3</td><td></td><td>300K</td><td>| 4.33</td><td>26.4</td><td>213</td></tr></tbody></table>'],\n",
       " 9: ['<table><thead><tr><th>Parser</th><th>Training</th><th>WSJ 23 F1</th></tr></thead><tbody><tr><td>Vinyals &amp; Kaiser el al. (2014)</td><td>WSJ only, discriminative</td><td>88.3</td></tr><tr><td>Petrov et al. (2006)</td><td>WSJ only, discriminative</td><td>90.4</td></tr><tr><td>Zhu et al. (2013) (40)</td><td>WSJ only, discriminative</td><td>90.4</td></tr><tr><td>Dyer et al. (2016)</td><td>WSJ only, discriminative</td><td>91.7</td></tr><tr><td>Transformer (4 layers)</td><td>WSJ only, discriminative</td><td>91.3</td></tr><tr><td>Zhu et al. (2013) [40]</td><td>semi-supervised</td><td>913</td></tr><tr><td>Huang &amp; Harper (2009)</td><td>semi-supervised</td><td>91.3</td></tr><tr><td>McClosky et al. (2006)</td><td>semi-supervised</td><td>92.1</td></tr><tr><td>Vinyals &amp; Kaiser el al. (2014)</td><td>semi-supervised</td><td>92.1</td></tr><tr><td>Transformer (4 layers)</td><td>semi-supervised</td><td>92.7</td></tr><tr><td>Luong et al. (2015) 23]</td><td>multi-task</td><td>93.0</td></tr><tr><td>Dyer et al. (2016)</td><td>generative</td><td>93.3</td></tr></tbody></table>']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the images from the CompositeElement objects\n",
    "def get_images_base64(chunks):\n",
    "    images_b64 = []\n",
    "    for chunk in chunks:\n",
    "        chunk_els = chunk.metadata.orig_elements\n",
    "        for el in chunk_els:\n",
    "            if \"Image\" in str(type(el)):\n",
    "                images_b64.append(el.metadata.image_base64)\n",
    "    return images_b64\n",
    "\n",
    "images = get_images_base64(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def display_base64_image(base64_code):\n",
    "    # Decode the base64 string to binary\n",
    "    image_data = base64.b64decode(base64_code)\n",
    "    # Display the image\n",
    "    display(Image(data=image_data))\n",
    "\n",
    "display_base64_image(images[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3a :Summarizing Tables and Text per Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"\n",
    "You are an assistant tasked with summarizing tables and text.\n",
    "Give a concise summary of the table or text.\n",
    "\n",
    "Respond only with the summary, no additional comment.\n",
    "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
    "Just give the summary as it is.\n",
    "\n",
    "Table or text chunk: {element}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Summary chain\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\" : 3})\n",
    "table_summaries = summarize_chain.batch(tables_html.values(), {\"max_concurrency\" : 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The table compares different layer types in terms of complexity per layer, sequential operations, and maximum path length. Self-Attention has complexity O(n? - d), with sequential operations and path length both O(1). Recurrent layers have a complexity of O(n - d?), with O(n) for sequential operations and O(n) for path length. Convolutional layers show complexity O(k-n-d?), with O(1) operations and a path length of O(logy(n)). Restricted Self-Attention has a complexity of O(r-n-d), operations denoted as \"ol\", and a maximum path length of O(n/r).',\n",
       " 'The table compares various translation models based on their performance in English to German (EN-DE) and English to French (EN-FR) translations, along with training requirements and computational cost (measured in FLOPs). Key models include ByteNet, GNMT, and Transformer, with EN-DE BLEU scores ranging from 23.75 to 28.4 and EN-FR scores from 38.1 to 41.8. Models such as MoE and ensembles of Deep-Att and GNMT show improved performance, while Transformer models, both base and big, have notable FLOP costs ranging from \\\\(10^{18}\\\\) to \\\\(10^{19}\\\\).',\n",
       " \"The table presents multiple configurations of models, categorized into groups labeled (A), (B), (C), and (E), with parameters such as N, dyoast, de, Rh, dy, and others. Each configuration includes values for metrics such as error rates and performance indicators. Notable observations include a base model with 6 settings yielding varied results, while model group (C) showcases a range of configurations with diminishing performance metrics as parameters change. Group (E) investigates the impact of using positional embedding instead of sinusoids. The final row features a 'big' model with 6 settings and increased N, resulting in higher output metrics.\",\n",
       " \"The table presents various parsers with their training types and corresponding WSJ 23 F1 scores. Discriminative methods include Vinyals & Kaiser (88.3), Petrov et al. (90.4), Zhu et al. (90.4), Dyer et al. (91.7), and Transformer (91.3). The semi-supervised category features Zhu et al. (913), Huang & Harper (91.3), McClosky et al. (92.1), Vinyals & Kaiser (92.1), and Transformer (92.7). The multi-task method by Luong et al. scores 93.0, while Dyer et al.'s generative approach achieves the highest score of 93.3.\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The paper introduces the Transformer, a new architecture for sequence transduction tasks that relies entirely on attention mechanisms, eliminating the need for recurrence and convolutions. The Transformer outperforms existing complex models in machine translation, achieving a BLEU score of 28.4 for English-to-German and 41.8 for English-to-French, while requiring less training time. The architecture also demonstrates strong generalization capabilities beyond translation tasks. The authors, associated with Google Brain and Google Research, contributed to various aspects of the model's development and evaluation.\",\n",
       " 'Recurrent neural networks, particularly long short-term memory and gated recurrent networks, have been key in sequence modeling tasks like language modeling and machine translation. However, their sequential nature limits parallelization and efficiency, especially with longer sequences. Attention mechanisms have improved dependency modeling across sequences, yet they are often used alongside recurrent networks. The proposed Transformer model eliminates recurrence, using only an attention mechanism, enabling significant parallelization and achieving state-of-the-art translation quality in a short training time. Other parallel models like Extended Neural GPU and ByteNet have limitations in learning long-range dependencies, whereas Transformers offer constant time operations for relating inputs and outputs. This work introduces the Transformer as the first model relying entirely on self-attention for its computations.',\n",
       " \"The table outlines the architecture of the Transformer model, which has an encoder-decoder structure used for neural sequence transduction. The encoder maps an input sequence to continuous representations, while the decoder generates an output sequence autoregressively. The Transformer comprises stacked self-attention and fully connected layers for both the encoder and decoder. The encoder has 6 identical layers with multi-head self-attention and feed-forward networks, utilizing residual connections and layer normalization. The decoder also has 6 identical layers but includes a third sub-layer for multi-head attention over the encoder's output, with a masking mechanism to ensure proper dependency for predictions. Both encoder and decoder outputs have a dimension of 512.\",\n",
       " 'An attention function maps a query and key-value pairs to an output, calculated as a weighted sum of values based on a compatibility function between queries and keys. Scaled Dot-Product Attention involves computing dot products of queries and keys, applying a softmax for weights, and outputs as Attention(Q,K,V) = softmax(QKT/√dk)V. It is faster and more space-efficient than additive attention, especially for larger dimensions, as it avoids issues with softmax gradients by scaling the dot products.',\n",
       " 'Multi-Head Attention enhances the attention mechanism by projecting queries, keys, and values multiple times, allowing parallel processing through several heads (h = 8) with reduced dimensions (dk = dv = dmodel/h = 64). This enables the model to attend to different representations simultaneously. The Transformer utilizes multi-head attention in three contexts: encoder-decoder attention (where queries are from the decoder and keys/values from the encoder), self-attention in the encoder (where all inputs come from the previous layer), and self-attention in the decoder (with masking to prevent future information flow).',\n",
       " 'Position-wise feed-forward networks in the encoder and decoder consist of two linear transformations separated by a ReLU activation, applied identically across positions but with different layer parameters. The input and output dimensions are 512, with an inner layer dimension of 2048. Learned embeddings convert input and output tokens to a vector dimension of 512, sharing weight matrices between embedding layers and the pre-softmax transformation. \\n\\nTable 1 outlines the complexity, sequential operations, and maximum path lengths for various layer types including self-attention, recurrent, and convolutional layers. \\n\\nPositional encoding is added to the input embeddings to provide order information since the model lacks recurrence or convolution. The chosen method uses sine and cosine functions of varying frequencies, facilitating relative position learning. Experiments showed that sinusoidal and learned positional embeddings yielded similar results, but the sinusoidal approach was preferred for potential extrapolation to longer sequences.',\n",
       " 'The section compares self-attention layers with recurrent and convolutional layers in terms of computational complexity, parallelization potential, and learning long-range dependencies. Self-attention layers require a constant number of sequential operations, making them faster than recurrent layers when the sequence length is shorter than the representation dimensionality. Convolutional layers need multiple layers to connect all input and output pairs, increasing path lengths. Self-attention also offers a potential for more interpretable models, as attention heads can learn distinct tasks and relate to the structure of sentences. Future work may explore limiting self-attention to local neighborhoods for better performance with long sequences.',\n",
       " 'The training regime for the models utilized the WMT 2014 English-German dataset with 4.5 million sentence pairs and the WMT 2014 English-French dataset with 36 million sentence pairs. Models were trained using 8 NVIDIA P100 GPUs, with base models trained for 100,000 steps over 12 hours and big models for 300,000 steps over 3.5 days. The Adam optimizer was utilized with a specific learning rate schedule based on warmup steps. Regularization techniques included residual dropout and label smoothing. The Transformer model achieved superior BLEU scores on both English-to-German and English-to-French tasks compared to previous state-of-the-art models while maintaining lower training costs measured in FLOPs.',\n",
       " 'The big transformer model achieved a new state-of-the-art BLEU score of 28.4 in the WMT 2014 English-to-German translation task, outperforming previous best models by over 2.0 BLEU, while training cost was notably lower. For English-to-French, it scored 41.0, also surpassing all single models and costing less than a quarter of the previous leading model. The model variations highlighted the effects of different architectural components on translation performance, particularly on the English-to-German dataset.',\n",
       " 'The text discusses the performance of a Transformer model in machine translation and English constituency parsing tasks. In machine translation, varying attention heads affects model quality, with too many heads or smaller attention keys degrading results. The model shows improvement with larger architectures and dropout usage. For English constituency parsing, a 4-layer Transformer trained on 40K sentences achieves competitive F1 scores, outperforming traditional RNN models and matching semi-supervised approaches on various benchmarks. The Transformer performs well without task-specific tuning, demonstrating its versatility across different tasks.',\n",
       " 'The Transformer model, introduced in this work, utilizes an attention-based architecture instead of recurrent layers, enabling faster training for translation tasks. It achieved state-of-the-art results in WMT 2014 English-to-German and English-to-French translations. Future research will explore applying the Transformer to other modalities beyond text and improving efficiency for large inputs and outputs, such as images and audio. The implementation code is publicly available. Acknowledgments are given to contributors for their insights and corrections.',\n",
       " \"The text discusses various studies related to advancements in neural networks, specifically in applications like computer vision and machine translation. Key papers include Szegedy et al.'s work on Inception architecture (2015), Vinyals et al.'s exploration of grammar as a foreign language (2015), Wu et al.'s Google neural machine translation system (2016), as well as Zhou et al.'s deep recurrent models for machine translation (2016). Additionally, it includes visualizations of attention mechanisms in neural networks, demonstrating how different attention heads in the encoder self-attention layer focus on different linguistic dependencies and structural features in sentences.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3b: Summarizing Images per Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt_template = \"\"\"Describe the image in detail. For context,\n",
    "                  the image is part of a research paper explaining the transformers\n",
    "                  architecture. Be specific about graphs, such as bar plots.\"\"\"\n",
    "messages = [\n",
    "    (\n",
    "        \"user\",\n",
    "        [\n",
    "            {\"type\": \"text\", \"text\": prompt_template},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "\n",
    "\n",
    "image_summaries = chain.batch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['image'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=[PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Describe the image in detail. For context,\\n                  the image is part of a research paper explaining the transformers\\n                  architecture. Be specific about graphs, such as bar plots.'), ImagePromptTemplate(input_variables=['image'], input_types={}, partial_variables={}, template={'url': 'data:image/jpeg;base64,{image}'})], additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x105f0b6e0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x31ca971a0>, root_client=<openai.OpenAI object at 0x31c9a1c40>, root_async_client=<openai.AsyncOpenAI object at 0x31ef3cdd0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a flowchart or diagram that summarizes a process related to the transformer architecture. Here's a detailed description:\n",
      "\n",
      "1. **Vertical Orientation**: The components are arranged in a vertical column, indicating a step-by-step flow of operations.\n",
      "\n",
      "2. **Top Section**:\n",
      "   - At the top, there is a block labeled \"MatMul\" in purple. This suggests that it is the final matrix multiplication step in the workflow.\n",
      "\n",
      "3. **Middle Components**: \n",
      "   - Below the top \"MatMul,\" there's a green box labeled \"SoftMax,\" indicating the application of the softmax function, which is typically used to convert scores into probabilities.\n",
      "   - Beneath that is a pink box labeled \"Mask (opt.),\" which suggests an optional masking step often used in attention mechanisms to handle padding or to prevent certain information from influencing others.\n",
      "   - Below this, there is a yellow box labeled \"Scale,\" which likely refers to scaling the attention scores by a factor, usually the square root of the dimensionality of the key vectors, to improve numerical stability.\n",
      "   - At the bottom of this section is another purple box labeled \"MatMul,\" indicating an earlier matrix multiplication step that is likely involved in computing the attention scores.\n",
      "\n",
      "4. **Input/Output Indicators**:\n",
      "   - Arrows indicate the direction of the flow:\n",
      "     - The bottom \"MatMul\" is connected to inputs labeled \"Q,\" \"K,\" and \"V,\" which typically represent queries, keys, and values, respectively, in the attention mechanism of transformers.\n",
      "     - The top \"MatMul\" indicates an output derived from the entire process.\n",
      "\n",
      "Overall, this diagram succinctly outlines the key operations involved in the attention mechanism of transformer models, illustrating how data flows through the different stages.\n"
     ]
    }
   ],
   "source": [
    "print(image_summaries[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Load the data and summaries to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/2jpnyd7j0m9790zmwsq_bvdw0000gn/T/ipykernel_56354/3922053165.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n",
      "/var/folders/b6/2jpnyd7j0m9790zmwsq_bvdw0000gn/T/ipykernel_56354/3922053165.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n"
     ]
    }
   ],
   "source": [
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the summaries and link to the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add texts\n",
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "summary_texts = [\n",
    "    Document(page_content=summary, metadata={id_key: doc_ids[i]}) for i, summary in enumerate(text_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "# Add tables\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "summary_tables = [\n",
    "    Document(page_content=summary, metadata={id_key: table_ids[i]}) for i, summary in enumerate(table_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_tables)\n",
    "retriever.docstore.mset(list(zip(table_ids, tables)))\n",
    "\n",
    "# Add image summaries\n",
    "img_ids = [str(uuid.uuid4()) for _ in images]\n",
    "summary_img = [\n",
    "    Document(page_content=summary, metadata={id_key: img_ids[i]}) for i, summary in enumerate(image_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_img)\n",
    "retriever.docstore.mset(list(zip(img_ids, images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.CompositeElement at 0x3224d5e20>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x3224d72f0>,\n",
       " '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',\n",
       " <unstructured.documents.elements.CompositeElement at 0x3224d7440>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_chunks = retriever.invoke(\"what is attention?\")\n",
    "retrieved_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2 Attention\n",
      "\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "\n",
      "3\n",
      "\n",
      "Scaled Dot-Product Attention\n",
      "\n",
      "Multi-Head Attention\n",
      "\n",
      "Linear\n",
      "\n",
      "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel.\n",
      "\n",
      "of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\n",
      "\n",
      "3.2.1 Scaled Dot-Product Attention\n",
      "\n",
      "We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the √ dk, and apply a softmax function to obtain the weights on the query with all keys, divide each by values.\n",
      "\n",
      "In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix Q. The keys and values are also packed together into matrices K and V . We compute the matrix of outputs as:\n",
      "\n",
      "Attention(Q,K,V ) = softmax( QKT √ dk )V (1)\n",
      "\n",
      "The two most commonly used attention functions are additive attention [2], and dot-product (multi- plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor 1√ of . Additive attention computes the compatibility function using a feed-forward network with dk a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code.\n",
      "\n",
      "While for small values of dk the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of dk [3]. We suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients 4. To counteract this effect, we scale the dot products by 1√ . dk\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3.2.2 Multi-Head Attention\n",
      "\n",
      "Instead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "\n",
      "‘To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, g -k = ves, qiki, has mean 0 and variance dx.\n",
      "\n",
      "4\n",
      "\n",
      "output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\n",
      "\n",
      "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
      "\n",
      "MultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i )\n",
      "\n",
      "Where the projections are parameter matrices W Q and W O ∈ Rhdv×dmodel. i ∈ Rdmodel×dk, W K i ∈ Rdmodel×dk, W V i ∈ Rdmodel×dv\n",
      "\n",
      "In this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\n",
      "\n",
      "3.2.3 Applications of Attention in our Model\n",
      "\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9].\n",
      "\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
      "\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "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\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 Why Self-Attention\n",
      "\n",
      "In this section we compare various aspects of self-attention layers to the recurrent and convolu- tional layers commonly used for mapping one variable-length sequence of symbol representations (x1,...,xn) to another sequence of equal length (z1,...,zn), with xi,zi ∈ Rd, such as a hidden layer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we consider three desiderata.\n",
      "\n",
      "One is the total computational complexity per layer. Another is the amount of computation that can be parallelized, as measured by the minimum number of sequential operations required.\n",
      "\n",
      "The third is the path length between long-range dependencies in the network. Learning long-range dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the ability to learn such dependencies is the length of the paths forward and backward signals have to traverse in the network. The shorter these paths between any combination of positions in the input and output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare the maximum path length between any two input and output positions in networks composed of the different layer types.\n",
      "\n",
      "As noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially executed operations, whereas a recurrent layer requires O(n) sequential operations. In terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence\n",
      "\n",
      "6\n",
      "\n",
      "length n is smaller than the representation dimensionality d, which is most often the case with sentence representations used by state-of-the-art models in machine translations, such as word-piece [38] and byte-pair [31] representations. To improve computational performance for tasks involving very long sequences, self-attention could be restricted to considering only a neighborhood of size r in the input sequence centered around the respective output position. This would increase the maximum path length to O(n/r). We plan to investigate this approach further in future work.\n",
      "\n",
      "A single convolutional layer with kernel width k < n does not connect all pairs of input and output positions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels, or O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest paths between any two positions in the network. Convolutional layers are generally more expensive than recurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity considerably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer, the approach we take in our model.\n",
      "\n",
      "As side benefit, self-attention could yield more interpretable models. We inspect attention distributions from our models and present and discuss examples in the appendix. Not only do individual attention heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic and semantic structure of the sentences.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc in retrieved_chunks:\n",
    "    print(str(doc) + \"\\n\\n\" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_docs(docs):\n",
    "    \"\"\"Split base64-encoded images and texts\"\"\"\n",
    "    b64 = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            b64decode(doc)\n",
    "            b64.append(doc)\n",
    "        except Exception as e:\n",
    "            text.append(doc)\n",
    "    return {\"images\": b64, \"texts\": text}\n",
    "\n",
    "\n",
    "def build_prompt(kwargs):\n",
    "\n",
    "    docs_by_type = kwargs[\"context\"]\n",
    "    user_question = kwargs[\"question\"]\n",
    "\n",
    "    context_text = \"\"\n",
    "    if len(docs_by_type[\"texts\"]) > 0:\n",
    "        for text_element in docs_by_type[\"texts\"]:\n",
    "            context_text += text_element.text\n",
    "\n",
    "    # construct prompt with context (including images)\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the question based only on the following context, which can include text, tables, and the below image.\n",
    "    Context: {context_text}\n",
    "    Question: {user_question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_content = [{\"type\": \"text\", \"text\": prompt_template}]\n",
    "\n",
    "    if len(docs_by_type[\"images\"]) > 0:\n",
    "        for image in docs_by_type[\"images\"]:\n",
    "            prompt_content.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            HumanMessage(content=prompt_content),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(parse_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(build_prompt)\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_with_sources = {\n",
    "    \"context\": retriever | RunnableLambda(parse_docs),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "} | RunnablePassthrough().assign(\n",
    "    response=(\n",
    "        RunnableLambda(build_prompt)\n",
    "        | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attention formula is given by:\n",
      "\n",
      "\\[\n",
      "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
      "\\]\n",
      "\n",
      "Where:\n",
      "- \\( Q \\) is the matrix of queries.\n",
      "- \\( K \\) is the matrix of keys.\n",
      "- \\( V \\) is the matrix of values.\n",
      "- \\( d_k \\) is the dimension of the keys.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    \"What is attention formula?\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The Transformer architecture is a neural network model designed primarily for sequence transduction tasks, utilizing a novel approach that relies entirely on attention mechanisms rather than recurrence or convolution. It consists of an encoder-decoder structure. \n",
      "\n",
      "### Key Components:\n",
      "1. **Encoder**: \n",
      "   - Composed of a stack of identical layers.\n",
      "   - Each layer has two main sub-layers:\n",
      "     - Multi-head self-attention mechanism.\n",
      "     - Position-wise fully connected feed-forward network.\n",
      "   - It employs residual connections and layer normalization.\n",
      "\n",
      "2. **Decoder**: \n",
      "   - Similar to the encoder but has an additional sub-layer for attending to the encoder's output.\n",
      "   - Incorporates masking to ensure that predictions for a given position depend only on previous positions.\n",
      "\n",
      "### Attention Mechanism:\n",
      "- The attention mechanism operates through:\n",
      "  - Computing queries (Q), keys (K), and values (V) from the input.\n",
      "  - Using matrix multiplications to derive attention scores, applying a softmax function to these scores, and using them to weigh the values (V).\n",
      "\n",
      "### Advantages:\n",
      "- Allows for parallelization during training and significantly reduces training time compared to traditional RNN-based models.\n",
      "- Achieves high performance on various tasks such as machine translation, with notable BLEU scores on benchmark datasets.\n",
      "\n",
      "Overall, the Transformer architecture has established a new state-of-the-art in multiple language processing tasks due to its efficiency and effectiveness.\n",
      "\n",
      "\n",
      "Context:\n",
      "3 Model Architecture\n",
      "\n",
      "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35]. Here, the encoder maps an input sequence of symbol representations (x1,...,xn) to a sequence of continuous representations z = (z1,...,zn). Given z, the decoder then generates an output sequence (y1,...,ym) of symbols one element at a time. At each step the model is auto-regressive [10], consuming the previously generated symbols as additional input when generating the next.\n",
      "\n",
      "2\n",
      "\n",
      "Output Probabilities Add & Norm Feed Forward Add & Norm Multi-Head Attention a, Add & Norm Add & Norm Feed Forward Nx | -+CAgc8 Norm) Add & Norm Masked Multi-Head Multi-Head Attention Attention Se a, ee a, Positional Positional Encoding @ © @ Encoding Input Output Embedding Embedding Inputs Outputs (shifted right)\n",
      "\n",
      "Figure 1: The Transformer - model architecture.\n",
      "\n",
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.\n",
      "\n",
      "3.1 Encoder and Decoder Stacks\n",
      "\n",
      "Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network. We employ a residual connection [11] around each of the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel = 512.\n",
      "\n",
      "Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i.\n",
      "Page number:  2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "3\n",
      "\n",
      "2023\n",
      "\n",
      "2\n",
      "\n",
      "0\n",
      "\n",
      "2\n",
      "\n",
      "g u A 2 ] L C . s c [ 7 v 2 6 7 3 0 . 6 0\n",
      "\n",
      "7\n",
      "\n",
      "1\n",
      "\n",
      ":\n",
      "\n",
      "v\n",
      "\n",
      "arXiv\n",
      "\n",
      "i\n",
      "\n",
      "X\n",
      "\n",
      "r\n",
      "\n",
      "a\n",
      "\n",
      "Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works.\n",
      "\n",
      "Attention Is All You Need\n",
      "\n",
      "Ashish Vaswani∗\n",
      "\n",
      "Google Brain\n",
      "\n",
      "avaswani@google.com\n",
      "\n",
      "Noam Shazeer∗ Google Brain noam@google.com\n",
      "\n",
      "Niki Parmar∗ Google Research nikip@google.com\n",
      "\n",
      "Jakob Uszkoreit∗\n",
      "\n",
      "Google Research usz@google.com\n",
      "\n",
      "Llion Jones∗\n",
      "\n",
      "Google Research llion@google.com\n",
      "\n",
      "Aidan N. Gomez∗ † University of Toronto aidan@cs.toronto.edu\n",
      "\n",
      "Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com\n",
      "\n",
      "Illia Polosukhin∗ ‡\n",
      "\n",
      "illia.polosukhin@gmail.com\n",
      "\n",
      "Abstract\n",
      "\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
      "\n",
      "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.\n",
      "\n",
      "†Work performed while at Google Brain.\n",
      "\n",
      "‡Work performed while at Google Research.\n",
      "\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n",
      "Page number:  1\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "7 Conclusion\n",
      "\n",
      "In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.\n",
      "\n",
      "For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\n",
      "\n",
      "We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours.\n",
      "\n",
      "The code we used to train and evaluate our models is available at https://github.com/ tensorflow/tensor2tensor.\n",
      "\n",
      "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.\n",
      "\n",
      "References\n",
      "\n",
      "[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.\n",
      "\n",
      "[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473, 2014.\n",
      "\n",
      "[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural machine translation architectures. CoRR, abs/1703.03906, 2017.\n",
      "\n",
      "[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine reading. arXiv preprint arXiv:1601.06733, 2016.\n",
      "\n",
      "10\n",
      "\n",
      "[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. CoRR, abs/1406.1078, 2014.\n",
      "\n",
      "[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint arXiv:1610.02357, 2016.\n",
      "\n",
      "[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\n",
      "\n",
      "[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural network grammars. In Proc. of NAACL, 2016.\n",
      "\n",
      "[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu- tional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\n",
      "\n",
      "[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013.\n",
      "\n",
      "[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im- age recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770–778, 2016.\n",
      "\n",
      "[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies, 2001.\n",
      "\n",
      "[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.\n",
      "\n",
      "[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 832–841. ACL, August 2009.\n",
      "\n",
      "[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\n",
      "\n",
      "[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural Information Processing Systems, (NIPS), 2016.\n",
      "\n",
      "[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference on Learning Representations (ICLR), 2016.\n",
      "\n",
      "[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko- ray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2, 2017.\n",
      "\n",
      "[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks. In International Conference on Learning Representations, 2017.\n",
      "\n",
      "[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n",
      "\n",
      "[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint arXiv:1703.10722, 2017.\n",
      "\n",
      "[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint arXiv:1703.03130, 2017.\n",
      "\n",
      "[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task sequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\n",
      "\n",
      "[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention- based neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\n",
      "\n",
      "11\n",
      "\n",
      "[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\n",
      "\n",
      "[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 152–159. ACL, June 2006.\n",
      "\n",
      "[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention model. In Empirical Methods in Natural Language Processing, 2016.\n",
      "\n",
      "[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization. arXiv preprint arXiv:1705.04304, 2017.\n",
      "\n",
      "[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July 2006.\n",
      "\n",
      "[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv preprint arXiv:1608.05859, 2016.\n",
      "\n",
      "[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909, 2015.\n",
      "\n",
      "[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint arXiv:1701.06538, 2017.\n",
      "\n",
      "[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi- nov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929–1958, 2014.\n",
      "\n",
      "[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates, Inc., 2015.\n",
      "\n",
      "[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\n",
      "Page number:  10\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chain_with_sources.invoke(\n",
    "    \"What is the transformer architecture?\"\n",
    ")\n",
    "\n",
    "print(\"Response:\", response['response'])\n",
    "\n",
    "print(\"\\n\\nContext:\")\n",
    "for text in response['context']['texts']:\n",
    "    print(text.text)\n",
    "    print(\"Page number: \", text.metadata.page_number)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "for image in response['context']['images']:\n",
    "    display_base64_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast  with PDF\n",
    "Create a Podcast of the PDF Summary with Specific Questions asked by RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prequsite Step \n",
    "\n",
    " Include any specific question as questions from the auidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_question_from_audience(l):\n",
    "     \n",
    "    response_outputs = \"\"\n",
    "\n",
    "    for i in l:\n",
    "        response = chain_with_sources.invoke(\n",
    "            i\n",
    "        )\n",
    "\n",
    "        final_output_response = f\"{response['response']} + \"\n",
    "\n",
    "        text = \"\"\n",
    "        for r in response['context']['texts']:\n",
    "            text = text + str(r)\n",
    "\n",
    "        final_output_response = f\"{response['response']}\\n\\nContext\\n\\n{text}\" \n",
    "\n",
    "        response_outputs = response_outputs + f\"Question:\\n{i}\\n\\n\" + f\"Output from relevant chunks of the PDF:\\n{final_output_response}\"\n",
    "\n",
    "    return response_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question:\\nWhat is Positional Encoding\\n\\nOutput from relevant chunks of the PDF:\\n**Positional Encoding** in the context of the Transformer model is a technique used to provide information about the position of tokens in a sequence. Since the model does not rely on recurrence or convolution, it injects information regarding the relative or absolute position of the tokens by adding positional encodings to the input embeddings at the encoder and decoder stacks. These positional encodings are designed to maintain the same dimensionality as the input embeddings.\\n\\nThe specific method used for these encodings involves sine and cosine functions of varying frequencies, defined mathematically as:\\n\\n- \\\\( PE(pos, 2i) = \\\\sin\\\\left(\\\\frac{pos}{10000^{2i/d_{model}}}\\\\right) \\\\)\\n- \\\\( PE(pos, 2i + 1) = \\\\cos\\\\left(\\\\frac{pos}{10000^{2i/d_{model}}}\\\\right) \\\\)\\n\\nwhere \\\\( pos \\\\) is the position and \\\\( i \\\\) is the dimension index. This methodological choice allows the model to learn relative positions effectively, and it can even generalize to longer sequences than those seen during training. \\n\\nIn summary, positional encoding helps the Transformer model to understand the order of tokens in a sequence, which is crucial for tasks involving sequential data.\\n\\nContext\\n\\n3.3 Position-wise Feed-Forward Networks\\n\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between.\\n\\nFFN(x) = max(0,xW1 + b1)W2 + b2 (2)\\n\\nWhile the linear transformations are the same across different positions, they use different parameters from layer to layer. Another way of describing this is as two convolutions with kernel size 1. The dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality dff = 2048.\\n\\n3.4 Embeddings and Softmax\\n\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor- mation and softmax function to convert the decoder output to predicted next-token probabilities. In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation, similar to [30]. In the embedding layers, we multiply those weights by √ dmodel.\\n\\n5\\n\\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations for different layer types. n is the sequence length, d is the representation dimension, k is the kernel size of convolutions and r the size of the neighborhood in restricted self-attention.\\n\\nLayer Type Complexity per Layer Sequential Maximum Path Length Operations Self-Attention O(n2 · d) O(1) O(1) Recurrent O(n · d2) O(n) O(n) Convolutional O(k · n · d2) O(1) O(logk(n)) Self-Attention (restricted) O(r · n · d) O(1) O(n/r)\\n\\n3.5 Positional Encoding\\n\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel as the embeddings, so that the two can be summed. There are many choices of positional encodings, learned and fixed [9].\\n\\nIn this work, we use sine and cosine functions of different frequencies:\\n\\nPE(pos,2i) = sin(pos/100002i/dmodel) PE(pos,2i+1) = cos(pos/100002i/dmodel)\\n\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding corresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of PEpos.\\n\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version because it may allow the model to extrapolate to sequence lengths longer than the ones encountered during training.3 Model Architecture\\n\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35]. Here, the encoder maps an input sequence of symbol representations (x1,...,xn) to a sequence of continuous representations z = (z1,...,zn). Given z, the decoder then generates an output sequence (y1,...,ym) of symbols one element at a time. At each step the model is auto-regressive [10], consuming the previously generated symbols as additional input when generating the next.\\n\\n2\\n\\nOutput Probabilities Add & Norm Feed Forward Add & Norm Multi-Head Attention a, Add & Norm Add & Norm Feed Forward Nx | -+CAgc8 Norm) Add & Norm Masked Multi-Head Multi-Head Attention Attention Se a, ee a, Positional Positional Encoding @ © @ Encoding Input Output Embedding Embedding Inputs Outputs (shifted right)\\n\\nFigure 1: The Transformer - model architecture.\\n\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.\\n\\n3.1 Encoder and Decoder Stacks\\n\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network. We employ a residual connection [11] around each of the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel = 512.\\n\\nDecoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i.Question:\\nWhat is Attention Mechanism Formula\\n\\nOutput from relevant chunks of the PDF:\\nThe Attention Mechanism formula, specifically for Scaled Dot-Product Attention, is given as:\\n\\n\\\\[\\n\\\\text{Attention}(Q, K, V) = \\\\text{softmax}\\\\left( \\\\frac{Q K^T}{\\\\sqrt{d_k}} \\\\right) V\\n\\\\]\\n\\nWhere:\\n- \\\\( Q \\\\) is the matrix of queries.\\n- \\\\( K \\\\) is the matrix of keys.\\n- \\\\( V \\\\) is the matrix of values.\\n- \\\\( d_k \\\\) is the dimension of the keys.\\n\\nContext\\n\\n3.2 Attention\\n\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n\\n3\\n\\nScaled Dot-Product Attention\\n\\nMulti-Head Attention\\n\\nLinear\\n\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel.\\n\\nof the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\\n\\n3.2.1 Scaled Dot-Product Attention\\n\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the √ dk, and apply a softmax function to obtain the weights on the query with all keys, divide each by values.\\n\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix Q. The keys and values are also packed together into matrices K and V . We compute the matrix of outputs as:\\n\\nAttention(Q,K,V ) = softmax( QKT √ dk )V (1)\\n\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi- plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor 1√ of . Additive attention computes the compatibility function using a feed-forward network with dk a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code.\\n\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of dk [3]. We suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients 4. To counteract this effect, we scale the dot products by 1√ . dk3.2.2 Multi-Head Attention\\n\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n\\n‘To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, g -k = ves, qiki, has mean 0 and variance dx.\\n\\n4\\n\\noutput values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\\n\\nMulti-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\\n\\nMultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i )\\n\\nWhere the projections are parameter matrices W Q and W O ∈ Rhdv×dmodel. i ∈ Rdmodel×dk, W K i ∈ Rdmodel×dk, W V i ∈ Rdmodel×dv\\n\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\\n\\n3.2.3 Applications of Attention in our Model\\n\\nThe Transformer uses multi-head attention in three different ways:\\n\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9].\\n\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.\\n\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_question_from_audience([\"What is Positional Encoding\", \"What is Attention Mechanism Formula\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a podcast_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_transcript = \"\"\"Example Podcast Transcript: \n",
    "<Person1> \"Hello listeners, and welcome to SID's Podcast - Your Personal Generative AI Podcast. Today, we're diving into a hot topic: Elon Musk and the fall of Tesla! Buckle up for a dynamic debate.\"\n",
    "</Person1><Person2> \"Absolutely! We're here to break down the factors behind Tesla's recent struggles and what role, if any, Elon Musk's decisions have played. Let's get into it!\"\n",
    "</Person2><Person1> \"Right on! On one hand, there's a strong argument that attributes Tesla's challenges to Musk's controversial decisions and unpredictable public behavior. Critics suggest that these factors have shaken investor confidence and contributed to market volatility.\"\n",
    "</Person1><Person2> \"On the other hand, some say that Tesla's current hurdles are simply part of the natural business cycle—impacted by market competition, supply chain disruptions, and evolving consumer trends. They believe Musk's bold, innovative vision continues to drive the company forward.\"\n",
    "</Person2><Person1> \"Exactly. So the burning question is: Are Tesla's setbacks really the result of Musk's actions, or are they just a temporary phase in the journey of a pioneering tech company?\"\n",
    "</Person1><Person2> \"Some point out that his high-profile social media antics and risky business maneuvers have created distractions, leading to an unstable market reaction. They argue that these issues highlight deeper problems in corporate governance.\"\n",
    "</Person2><Person1> \"Yet others counter that disruptive innovation is never a smooth ride. Musk's daring approach has propelled Tesla to unprecedented heights before, and current challenges might simply be a growing pain rather than a sign of irreversible decline.\"\n",
    "</Person1><Person2> \"Indeed. It really raises questions about leadership and accountability in high-stakes tech ventures. Can a visionary leader navigate such turbulence without compromising the company's mission?\"\n",
    "</Person2><Person1> \"That's the million-dollar question. Whether you view it as a fall from grace or just a strategic pause, this discussion challenges us to reconsider the complex relationship between a leader's personality, corporate strategy, and market dynamics.\"\n",
    "</Person1><Person2> \"Well said! It's a multifaceted issue that goes beyond assigning blame, reminding us that in the world of disruptive technology, highs and lows are part of the journey.\"\n",
    "</Person2><Person1> \"Absolutely. That wraps up today's deep dive into Elon Musk and the challenges Tesla faces. Thanks for joining us on SID's Podcast. Until next time, stay curious and keep exploring!\"\n",
    "</Person1><Person2> \"Catch you all on the next episode!\"\n",
    "</Person2>\"\"\"\n",
    "\n",
    "text_summary = \"Text Summaries:\\n\" + \"\\n\".join(text_summaries)\n",
    "table_summary = \"Table Summaries:\\n\" + \"\\n\".join(table_summaries)\n",
    "image_summary = \"Image Summaries:\\n\" + \"\\n\".join(image_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant in TV channel tasked with creating a podcast transcript for two Hosts, hosting a podcast named SID's Podcast. Your task is to use Text Summaries, Table Summaries, Images Summaries and Specific Questions (From Audience) with context from a pdf to create a transcript similar to the given transcript (include html tags) in the output.\n",
      "\n",
      "Text Summaries:\n",
      "The paper introduces the Transformer, a new architecture for sequence transduction tasks that relies entirely on attention mechanisms, eliminating the need for recurrence and convolutions. The Transformer outperforms existing complex models in machine translation, achieving a BLEU score of 28.4 for English-to-German and 41.8 for English-to-French, while requiring less training time. The architecture also demonstrates strong generalization capabilities beyond translation tasks. The authors, associated with Google Brain and Google Research, contributed to various aspects of the model's development and evaluation.\n",
      "Recurrent neural networks, particularly long short-term memory and gated recurrent networks, have been key in sequence modeling tasks like language modeling and machine translation. However, their sequential nature limits parallelization and efficiency, especially with longer sequences. Attention mechanisms have improved dependency modeling across sequences, yet they are often used alongside recurrent networks. The proposed Transformer model eliminates recurrence, using only an attention mechanism, enabling significant parallelization and achieving state-of-the-art translation quality in a short training time. Other parallel models like Extended Neural GPU and ByteNet have limitations in learning long-range dependencies, whereas Transformers offer constant time operations for relating inputs and outputs. This work introduces the Transformer as the first model relying entirely on self-attention for its computations.\n",
      "The table outlines the architecture of the Transformer model, which has an encoder-decoder structure used for neural sequence transduction. The encoder maps an input sequence to continuous representations, while the decoder generates an output sequence autoregressively. The Transformer comprises stacked self-attention and fully connected layers for both the encoder and decoder. The encoder has 6 identical layers with multi-head self-attention and feed-forward networks, utilizing residual connections and layer normalization. The decoder also has 6 identical layers but includes a third sub-layer for multi-head attention over the encoder's output, with a masking mechanism to ensure proper dependency for predictions. Both encoder and decoder outputs have a dimension of 512.\n",
      "An attention function maps a query and key-value pairs to an output, calculated as a weighted sum of values based on a compatibility function between queries and keys. Scaled Dot-Product Attention involves computing dot products of queries and keys, applying a softmax for weights, and outputs as Attention(Q,K,V) = softmax(QKT/√dk)V. It is faster and more space-efficient than additive attention, especially for larger dimensions, as it avoids issues with softmax gradients by scaling the dot products.\n",
      "Multi-Head Attention enhances the attention mechanism by projecting queries, keys, and values multiple times, allowing parallel processing through several heads (h = 8) with reduced dimensions (dk = dv = dmodel/h = 64). This enables the model to attend to different representations simultaneously. The Transformer utilizes multi-head attention in three contexts: encoder-decoder attention (where queries are from the decoder and keys/values from the encoder), self-attention in the encoder (where all inputs come from the previous layer), and self-attention in the decoder (with masking to prevent future information flow).\n",
      "Position-wise feed-forward networks in the encoder and decoder consist of two linear transformations separated by a ReLU activation, applied identically across positions but with different layer parameters. The input and output dimensions are 512, with an inner layer dimension of 2048. Learned embeddings convert input and output tokens to a vector dimension of 512, sharing weight matrices between embedding layers and the pre-softmax transformation. \n",
      "\n",
      "Table 1 outlines the complexity, sequential operations, and maximum path lengths for various layer types including self-attention, recurrent, and convolutional layers. \n",
      "\n",
      "Positional encoding is added to the input embeddings to provide order information since the model lacks recurrence or convolution. The chosen method uses sine and cosine functions of varying frequencies, facilitating relative position learning. Experiments showed that sinusoidal and learned positional embeddings yielded similar results, but the sinusoidal approach was preferred for potential extrapolation to longer sequences.\n",
      "The section compares self-attention layers with recurrent and convolutional layers in terms of computational complexity, parallelization potential, and learning long-range dependencies. Self-attention layers require a constant number of sequential operations, making them faster than recurrent layers when the sequence length is shorter than the representation dimensionality. Convolutional layers need multiple layers to connect all input and output pairs, increasing path lengths. Self-attention also offers a potential for more interpretable models, as attention heads can learn distinct tasks and relate to the structure of sentences. Future work may explore limiting self-attention to local neighborhoods for better performance with long sequences.\n",
      "The training regime for the models utilized the WMT 2014 English-German dataset with 4.5 million sentence pairs and the WMT 2014 English-French dataset with 36 million sentence pairs. Models were trained using 8 NVIDIA P100 GPUs, with base models trained for 100,000 steps over 12 hours and big models for 300,000 steps over 3.5 days. The Adam optimizer was utilized with a specific learning rate schedule based on warmup steps. Regularization techniques included residual dropout and label smoothing. The Transformer model achieved superior BLEU scores on both English-to-German and English-to-French tasks compared to previous state-of-the-art models while maintaining lower training costs measured in FLOPs.\n",
      "The big transformer model achieved a new state-of-the-art BLEU score of 28.4 in the WMT 2014 English-to-German translation task, outperforming previous best models by over 2.0 BLEU, while training cost was notably lower. For English-to-French, it scored 41.0, also surpassing all single models and costing less than a quarter of the previous leading model. The model variations highlighted the effects of different architectural components on translation performance, particularly on the English-to-German dataset.\n",
      "The text discusses the performance of a Transformer model in machine translation and English constituency parsing tasks. In machine translation, varying attention heads affects model quality, with too many heads or smaller attention keys degrading results. The model shows improvement with larger architectures and dropout usage. For English constituency parsing, a 4-layer Transformer trained on 40K sentences achieves competitive F1 scores, outperforming traditional RNN models and matching semi-supervised approaches on various benchmarks. The Transformer performs well without task-specific tuning, demonstrating its versatility across different tasks.\n",
      "The Transformer model, introduced in this work, utilizes an attention-based architecture instead of recurrent layers, enabling faster training for translation tasks. It achieved state-of-the-art results in WMT 2014 English-to-German and English-to-French translations. Future research will explore applying the Transformer to other modalities beyond text and improving efficiency for large inputs and outputs, such as images and audio. The implementation code is publicly available. Acknowledgments are given to contributors for their insights and corrections.\n",
      "The text discusses various studies related to advancements in neural networks, specifically in applications like computer vision and machine translation. Key papers include Szegedy et al.'s work on Inception architecture (2015), Vinyals et al.'s exploration of grammar as a foreign language (2015), Wu et al.'s Google neural machine translation system (2016), as well as Zhou et al.'s deep recurrent models for machine translation (2016). Additionally, it includes visualizations of attention mechanisms in neural networks, demonstrating how different attention heads in the encoder self-attention layer focus on different linguistic dependencies and structural features in sentences.\n",
      "\n",
      "Table Summaries:\n",
      "The table compares different layer types in terms of complexity per layer, sequential operations, and maximum path length. Self-Attention has complexity O(n? - d), with sequential operations and path length both O(1). Recurrent layers have a complexity of O(n - d?), with O(n) for sequential operations and O(n) for path length. Convolutional layers show complexity O(k-n-d?), with O(1) operations and a path length of O(logy(n)). Restricted Self-Attention has a complexity of O(r-n-d), operations denoted as \"ol\", and a maximum path length of O(n/r).\n",
      "The table compares various translation models based on their performance in English to German (EN-DE) and English to French (EN-FR) translations, along with training requirements and computational cost (measured in FLOPs). Key models include ByteNet, GNMT, and Transformer, with EN-DE BLEU scores ranging from 23.75 to 28.4 and EN-FR scores from 38.1 to 41.8. Models such as MoE and ensembles of Deep-Att and GNMT show improved performance, while Transformer models, both base and big, have notable FLOP costs ranging from \\(10^{18}\\) to \\(10^{19}\\).\n",
      "The table presents multiple configurations of models, categorized into groups labeled (A), (B), (C), and (E), with parameters such as N, dyoast, de, Rh, dy, and others. Each configuration includes values for metrics such as error rates and performance indicators. Notable observations include a base model with 6 settings yielding varied results, while model group (C) showcases a range of configurations with diminishing performance metrics as parameters change. Group (E) investigates the impact of using positional embedding instead of sinusoids. The final row features a 'big' model with 6 settings and increased N, resulting in higher output metrics.\n",
      "The table presents various parsers with their training types and corresponding WSJ 23 F1 scores. Discriminative methods include Vinyals & Kaiser (88.3), Petrov et al. (90.4), Zhu et al. (90.4), Dyer et al. (91.7), and Transformer (91.3). The semi-supervised category features Zhu et al. (913), Huang & Harper (91.3), McClosky et al. (92.1), Vinyals & Kaiser (92.1), and Transformer (92.7). The multi-task method by Luong et al. scores 93.0, while Dyer et al.'s generative approach achieves the highest score of 93.3.\n",
      "\n",
      "Image Summaries:\n",
      "The image depicts a flowchart illustrating the architecture of a Transformer model, commonly used in natural language processing tasks. Here’s a detailed description of its components:\n",
      "\n",
      "1. **Positional Encoding**: At the bottom left and bottom right, \"Positional Encoding\" is indicated. It provides the model with information about the position of each token in the input sequence.\n",
      "\n",
      "2. **Input and Output Embeddings**: Below the positional encoding, there are blocks labeled \"Input Embedding\" (left) and \"Output Embedding\" (right), showing the transformation of tokens into embeddings. The output embeddings are noted to be \"shifted right,\" which is a standard approach for autoregressive modeling.\n",
      "\n",
      "3. **N Layers (Nx)**: The central section is segmented into two identical layers, each labeled \"Nx,\" indicating that these layers can be stacked multiple times for deeper architectures. \n",
      "\n",
      "4. **Multi-Head Attention**: Each layer features modules for \"Multi-Head Attention.\" This component allows the model to focus on different parts of the input sequence simultaneously, learning various contextual relationships.\n",
      "\n",
      "5. **Masked Multi-Head Attention**: The right side Layer also contains \"Masked Multi-Head Attention\" to ensure that predictions for a certain position depend only on the known outputs preceding that position, which is vital during training.\n",
      "\n",
      "6. **Feed Forward Networks**: Each layer includes a \"Feed Forward\" module, highlighted in blue, which applies transformations to the output of the attention layers.\n",
      "\n",
      "7. **Add & Norm**: Between each major component (both attention and feed-forward), there are blocks labeled \"Add & Norm,\" signifying layer normalization and residual connections. These connections help in stabilizing the training of deep networks.\n",
      "\n",
      "8. **Output Probabilities**: At the top of the right section, an \"Output Probabilities\" block is present, indicating that the final output of the model, after passing through a \"Linear\" transformation and a \"Softmax\" function, generates probability distributions over the vocabulary for predicting the next token.\n",
      "\n",
      "Overall, the diagram emphasizes the sequential flow of data through the model's architecture, highlighting the importance of attention mechanisms and normalization processes in modern deep learning applications.\n",
      "The image depicts a flowchart or diagram that summarizes a process related to the transformer architecture. Here's a detailed description:\n",
      "\n",
      "1. **Vertical Orientation**: The components are arranged in a vertical column, indicating a step-by-step flow of operations.\n",
      "\n",
      "2. **Top Section**:\n",
      "   - At the top, there is a block labeled \"MatMul\" in purple. This suggests that it is the final matrix multiplication step in the workflow.\n",
      "\n",
      "3. **Middle Components**: \n",
      "   - Below the top \"MatMul,\" there's a green box labeled \"SoftMax,\" indicating the application of the softmax function, which is typically used to convert scores into probabilities.\n",
      "   - Beneath that is a pink box labeled \"Mask (opt.),\" which suggests an optional masking step often used in attention mechanisms to handle padding or to prevent certain information from influencing others.\n",
      "   - Below this, there is a yellow box labeled \"Scale,\" which likely refers to scaling the attention scores by a factor, usually the square root of the dimensionality of the key vectors, to improve numerical stability.\n",
      "   - At the bottom of this section is another purple box labeled \"MatMul,\" indicating an earlier matrix multiplication step that is likely involved in computing the attention scores.\n",
      "\n",
      "4. **Input/Output Indicators**:\n",
      "   - Arrows indicate the direction of the flow:\n",
      "     - The bottom \"MatMul\" is connected to inputs labeled \"Q,\" \"K,\" and \"V,\" which typically represent queries, keys, and values, respectively, in the attention mechanism of transformers.\n",
      "     - The top \"MatMul\" indicates an output derived from the entire process.\n",
      "\n",
      "Overall, this diagram succinctly outlines the key operations involved in the attention mechanism of transformer models, illustrating how data flows through the different stages.\n",
      "The image depicts a simplified architecture of the transformer model, focusing on the scaled dot-product attention mechanism. \n",
      "\n",
      "### Key Features of the Image:\n",
      "\n",
      "1. **Elements and Structure**:\n",
      "   - At the bottom, three separate \"Linear\" blocks are labeled as **V** (Values), **K** (Keys), and **Q** (Queries). These represent the inputs to the attention mechanism.\n",
      "   - Each \"Linear\" block suggests that a linear transformation is applied to the input vectors to produce the corresponding representations.\n",
      "\n",
      "2. **Attention Mechanism**:\n",
      "   - Above the Linear blocks is a large purple box labeled **\"Scaled Dot-Product Attention.\"** This emphasizes the core component of the transformer architecture, where the queries, keys, and values interact to compute attention scores.\n",
      "   - There are arrows indicating the flow of information from the three Linear blocks into the attention box, demonstrating how the inputs are combined.\n",
      "\n",
      "3. **Concatenation and Output**:\n",
      "   - Above the attention block is a yellow box labeled **\"Concat.\"** This suggests that the outputs from the attention mechanism will be concatenated.\n",
      "   - The image indicates that the output from the \"Scaled Dot-Product Attention\" flows into this concatenation step, which may further feed into additional processing.\n",
      "\n",
      "4. **Arrows and Flow**:\n",
      "   - The use of arrows illustrates the direction of data flow throughout the architecture. The arrows are labeled to indicate the connections, suggesting a flow from inputs to the scaled attention mechanism and then to the concatenation layer.\n",
      "\n",
      "5. **Notation**:\n",
      "   - There is a small letter \"h\" at the right of the attention box, possibly indicating an output or a hidden state resulting from the attention process.\n",
      "\n",
      "Overall, the image effectively captures the essential elements of the transformer's attention mechanism, focusing on the role of queries, keys, and values, as well as the concatenation of outputs.\n",
      "\n",
      "The image appears to illustrate the attention mechanism within the transformer architecture, specifically highlighting how certain words or tokens interact with others in a sentence. \n",
      "\n",
      "1. **Central Vertical Line**: In the middle, the word \"2009\" stands out, possibly indicating it as the focus token for the attention calculation.\n",
      "\n",
      "2. **Surrounding Tokens**: To the left and right of \"2009,\" there are multiple tokens (words) displayed in a vertical orientation. These tokens include phrases like \"It,\" \"is,\" \"in,\" \"this,\" \"spirit,\" and others. The left side seems to represent a collection of words leading up to \"2009,\" while the right side presents subsequent words stemming from it.\n",
      "\n",
      "3. **Attention Lines**: There are colored lines connecting \"2009\" to several other tokens, showcasing how the transformer attends to different parts of the input. The colors of these lines vary, denoting different aspects of the attention weights. Some lines are thinner, indicating less attention, while thicker lines suggest higher significance.\n",
      "\n",
      "4. **Highlighted Words**: The words on the right side culminate in phrases like \"making the registration\" and \"more difficult,\" indicating a potential output generated based on the input context. \n",
      "\n",
      "5. **Padding Tokens**: At the far right and bottom, there are several \"<pad>\" and \"<EOS>\" tokens. This suggests that these tokens are used for padding the sequence and marking the end of the sequence, common in transformer architectures for uniform input lengths.\n",
      "\n",
      "Overall, the image exemplifies how transformers manage contextual relationships between words through the attention mechanism, allowing for nuanced understanding and generation of language based on prior context.\n",
      "The image presents a visualization likely illustrating the attention mechanism within a Transformer architecture. Here's a detailed description of its components:\n",
      "\n",
      "1. **Text Tokens**: The horizontal axis consists of various tokens (words) arranged in a sequence. These tokens include \"The,\" \"Law,\" \"will,\" \"never,\" \"be,\" \"perfect,\" \"but,\" \"its,\" \"application,\" \"should,\" \"be,\" \"just,\" \"this,\" \"is,\" \"what,\" \"we,\" \"are,\" \"missing,\" \"in,\" \"my,\" \"opinion,\" \"<EOS>,\" and \"<pad>.\" Notably, \"Law\" is highlighted in purple to indicate its particular significance or to show that it's a key token in the pattern of relationships being examined.\n",
      "\n",
      "2. **Connections**: There are numerous lines connecting different tokens. Each line’s opacity varies, indicating the strength or weight of the attention between pairs of tokens. The lines are mainly presented in a light purple hue, with darker lines suggesting stronger relationships or attentional weights.\n",
      "\n",
      "3. **Key Output Tokens**: On the right side, tokens like \"<EOS>\" (indicating the end of a sentence or sequence) and \"<pad>\" (usually for padding sequences in batch processing) are also present, highlighting that the model takes these cues into account when processing the input.\n",
      "\n",
      "4. **Arrow Visualization**: The lines connecting the tokens may suggest a flow of attention, where the model determines which parts of the input sequence (left tokens) are more relevant to the output tokens (right). This reflects how different words in the input contribute to understanding or generating subsequent words.\n",
      "\n",
      "5. **Layout**: The spatial organization of the tokens suggests a sequential process, with input tokens on the left and inferred or generated tokens on the right, emphasizing the direction of processing in the transformer model.\n",
      "\n",
      "Overall, this image serves as a graphical representation of the intricate relationships and attention weights between different tokens in a Transformer model's architecture, crucial for understanding how these neural networks process language.\n",
      "The image is a visualization of connections between words in a transformer architecture, likely demonstrating attention mechanisms. Here’s a detailed breakdown:\n",
      "\n",
      "1. **Structure**: The image consists of several words arranged horizontally. These words form two distinct groups or segments in two rows, with lines connecting them.\n",
      "\n",
      "2. **Words**: \n",
      "   - The left side includes words like “The,” “Law,” “will,” “never,” “be,” “perfect,” etc.\n",
      "   - The right side features terms such as “this,” “is,” “what,” “we,” “are,” “missing,” along with special tokens like `<EOS>` (End of Sentence) and `<pad>` (padding token).\n",
      "\n",
      "3. **Connections**: \n",
      "   - The connections are represented by lines between words. The lines vary in thickness, indicating the strength or weight of attention between these words.\n",
      "   - Thicker, darker green lines suggest stronger attention or relevance, while thinner, lighter lines indicate weaker connections.\n",
      "\n",
      "4. **Color Gradient**: The gradient from light to dark green signifies varying levels of attention strength, which aligns with how transformers implement attention mechanisms in processing language.\n",
      "\n",
      "5. **Implications**: This visualization likely contextualizes how the transformer model pays attention to different words when processing language, highlighting relationships and dependencies that the model identifies during training or inference.\n",
      "\n",
      "Overall, the image effectively conveys how specific words in a sentence are interconnected through the attention mechanism of transformers, illustrating the complexity and depth of language understanding these models possess.\n",
      "The image depicts a sequence of words arranged in a linear format, resembling a sentence or a series of phrases related to a topic, likely presented in a research context about transformers in machine learning. The words are set vertically, with some words appearing multiple times, particularly \"be\" and \"should.\" \n",
      "\n",
      "Connections between words are illustrated by lines—these lines vary in thickness and opacity, indicating the strength or relevance of associations between different words. The lines are primarily red, with some being lighter, suggesting varying degrees of relationship intensity. For instance, there are multiple lines connecting \"should\" to several other words, indicating its significant role in the phrasing.\n",
      "\n",
      "At the end of the sequence, special tokens like `<EOS>` and `<pad>` appear, likely representing the end of a sentence and padding in a sequence model, respectively. This layout provides a visual representation of how words in a transformer architecture are linked, emphasizing attention mechanisms that prioritize certain words over others based on contextual relevance in generating or understanding language.\n",
      "\n",
      "Question:\n",
      "What is Positional Encoding\n",
      "\n",
      "Output from relevant chunks of the PDF:\n",
      "Positional Encoding is a technique used in transformer models to inject information about the relative or absolute position of tokens in a sequence. Since transformers lack recurrence and convolution, positional encodings allow the model to understand the order of tokens. \n",
      "\n",
      "In this model, the positional encodings are added to the input embeddings at the bottom of the encoder and decoder stacks. The encodings are defined mathematically using sine and cosine functions of different frequencies:\n",
      "\n",
      "- For even dimensions: \\( PE(pos, 2i) = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) \\)\n",
      "- For odd dimensions: \\( PE(pos, 2i+1) = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right) \\)\n",
      "\n",
      "Here, \\( pos \\) represents the position of the token in the sequence, and \\( i \\) denotes the dimension. This choice allows the model to learn to attend to relative positions, facilitating the processing of various sequence lengths beyond those encountered during training.\n",
      "\n",
      "Context\n",
      "\n",
      "3.3 Position-wise Feed-Forward Networks\n",
      "\n",
      "In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between.\n",
      "\n",
      "FFN(x) = max(0,xW1 + b1)W2 + b2 (2)\n",
      "\n",
      "While the linear transformations are the same across different positions, they use different parameters from layer to layer. Another way of describing this is as two convolutions with kernel size 1. The dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality dff = 2048.\n",
      "\n",
      "3.4 Embeddings and Softmax\n",
      "\n",
      "Similarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor- mation and softmax function to convert the decoder output to predicted next-token probabilities. In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation, similar to [30]. In the embedding layers, we multiply those weights by √ dmodel.\n",
      "\n",
      "5\n",
      "\n",
      "Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations for different layer types. n is the sequence length, d is the representation dimension, k is the kernel size of convolutions and r the size of the neighborhood in restricted self-attention.\n",
      "\n",
      "Layer Type Complexity per Layer Sequential Maximum Path Length Operations Self-Attention O(n2 · d) O(1) O(1) Recurrent O(n · d2) O(n) O(n) Convolutional O(k · n · d2) O(1) O(logk(n)) Self-Attention (restricted) O(r · n · d) O(1) O(n/r)\n",
      "\n",
      "3.5 Positional Encoding\n",
      "\n",
      "Since our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel as the embeddings, so that the two can be summed. There are many choices of positional encodings, learned and fixed [9].\n",
      "\n",
      "In this work, we use sine and cosine functions of different frequencies:\n",
      "\n",
      "PE(pos,2i) = sin(pos/100002i/dmodel) PE(pos,2i+1) = cos(pos/100002i/dmodel)\n",
      "\n",
      "where pos is the position and i is the dimension. That is, each dimension of the positional encoding corresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of PEpos.\n",
      "\n",
      "We also experimented with using learned positional embeddings [9] instead, and found that the two versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version because it may allow the model to extrapolate to sequence lengths longer than the ones encountered during training.3 Model Architecture\n",
      "\n",
      "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35]. Here, the encoder maps an input sequence of symbol representations (x1,...,xn) to a sequence of continuous representations z = (z1,...,zn). Given z, the decoder then generates an output sequence (y1,...,ym) of symbols one element at a time. At each step the model is auto-regressive [10], consuming the previously generated symbols as additional input when generating the next.\n",
      "\n",
      "2\n",
      "\n",
      "Output Probabilities Add & Norm Feed Forward Add & Norm Multi-Head Attention a, Add & Norm Add & Norm Feed Forward Nx | -+CAgc8 Norm) Add & Norm Masked Multi-Head Multi-Head Attention Attention Se a, ee a, Positional Positional Encoding @ © @ Encoding Input Output Embedding Embedding Inputs Outputs (shifted right)\n",
      "\n",
      "Figure 1: The Transformer - model architecture.\n",
      "\n",
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.\n",
      "\n",
      "3.1 Encoder and Decoder Stacks\n",
      "\n",
      "Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network. We employ a residual connection [11] around each of the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel = 512.\n",
      "\n",
      "Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i.Question:\n",
      "What is Attention Mechanism Formula\n",
      "\n",
      "Output from relevant chunks of the PDF:\n",
      "The Attention Mechanism formula is expressed as follows:\n",
      "\n",
      "\\[\n",
      "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
      "\\]\n",
      "\n",
      "Where:\n",
      "- \\(Q\\) represents the queries,\n",
      "- \\(K\\) denotes the keys,\n",
      "- \\(V\\) stands for the values,\n",
      "- \\(d_k\\) is the dimension of the keys. \n",
      "\n",
      "This formula allows for the computation of the attention outputs based on the compatibility of the queries and keys, adjusted by the scaling factor \\(1/\\sqrt{d_k}\\).\n",
      "\n",
      "Context\n",
      "\n",
      "3.2 Attention\n",
      "\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "\n",
      "3\n",
      "\n",
      "Scaled Dot-Product Attention\n",
      "\n",
      "Multi-Head Attention\n",
      "\n",
      "Linear\n",
      "\n",
      "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel.\n",
      "\n",
      "of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\n",
      "\n",
      "3.2.1 Scaled Dot-Product Attention\n",
      "\n",
      "We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the √ dk, and apply a softmax function to obtain the weights on the query with all keys, divide each by values.\n",
      "\n",
      "In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix Q. The keys and values are also packed together into matrices K and V . We compute the matrix of outputs as:\n",
      "\n",
      "Attention(Q,K,V ) = softmax( QKT √ dk )V (1)\n",
      "\n",
      "The two most commonly used attention functions are additive attention [2], and dot-product (multi- plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor 1√ of . Additive attention computes the compatibility function using a feed-forward network with dk a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code.\n",
      "\n",
      "While for small values of dk the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of dk [3]. We suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients 4. To counteract this effect, we scale the dot products by 1√ . dk3.2.2 Multi-Head Attention\n",
      "\n",
      "Instead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
      "\n",
      "‘To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, g -k = ves, qiki, has mean 0 and variance dx.\n",
      "\n",
      "4\n",
      "\n",
      "output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2.\n",
      "\n",
      "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
      "\n",
      "MultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i )\n",
      "\n",
      "Where the projections are parameter matrices W Q and W O ∈ Rhdv×dmodel. i ∈ Rdmodel×dk, W K i ∈ Rdmodel×dk, W V i ∈ Rdmodel×dv\n",
      "\n",
      "In this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\n",
      "\n",
      "3.2.3 Applications of Attention in our Model\n",
      "\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9].\n",
      "\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
      "\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2.\n",
      "\n",
      "Example Podcast Transcript: \n",
      "<Person1> \"Hello listeners, and welcome to SID's Podcast - Your Personal Generative AI Podcast. Today, we're diving into a hot topic: Elon Musk and the fall of Tesla! Buckle up for a dynamic debate.\"\n",
      "</Person1><Person2> \"Absolutely! We're here to break down the factors behind Tesla's recent struggles and what role, if any, Elon Musk's decisions have played. Let's get into it!\"\n",
      "</Person2><Person1> \"Right on! On one hand, there's a strong argument that attributes Tesla's challenges to Musk's controversial decisions and unpredictable public behavior. Critics suggest that these factors have shaken investor confidence and contributed to market volatility.\"\n",
      "</Person1><Person2> \"On the other hand, some say that Tesla's current hurdles are simply part of the natural business cycle—impacted by market competition, supply chain disruptions, and evolving consumer trends. They believe Musk's bold, innovative vision continues to drive the company forward.\"\n",
      "</Person2><Person1> \"Exactly. So the burning question is: Are Tesla's setbacks really the result of Musk's actions, or are they just a temporary phase in the journey of a pioneering tech company?\"\n",
      "</Person1><Person2> \"Some point out that his high-profile social media antics and risky business maneuvers have created distractions, leading to an unstable market reaction. They argue that these issues highlight deeper problems in corporate governance.\"\n",
      "</Person2><Person1> \"Yet others counter that disruptive innovation is never a smooth ride. Musk's daring approach has propelled Tesla to unprecedented heights before, and current challenges might simply be a growing pain rather than a sign of irreversible decline.\"\n",
      "</Person1><Person2> \"Indeed. It really raises questions about leadership and accountability in high-stakes tech ventures. Can a visionary leader navigate such turbulence without compromising the company's mission?\"\n",
      "</Person2><Person1> \"That's the million-dollar question. Whether you view it as a fall from grace or just a strategic pause, this discussion challenges us to reconsider the complex relationship between a leader's personality, corporate strategy, and market dynamics.\"\n",
      "</Person1><Person2> \"Well said! It's a multifaceted issue that goes beyond assigning blame, reminding us that in the world of disruptive technology, highs and lows are part of the journey.\"\n",
      "</Person2><Person1> \"Absolutely. That wraps up today's deep dive into Elon Musk and the challenges Tesla faces. Thanks for joining us on SID's Podcast. Until next time, stay curious and keep exploring!\"\n",
      "</Person1><Person2> \"Catch you all on the next episode!\"\n",
      "</Person2>\n",
      "\n",
      "Add specific questions by audience at the end of the podcast in a QA session stating something like : 'Now lets us address the questions from our Audience' \n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"You are an assistant in TV channel tasked with creating a podcast transcript for two Hosts, hosting a podcast named SID's Podcast. Your task is to use Text Summaries, Table Summaries, Images Summaries and Specific Questions (From Audience) with context from a pdf to create a transcript similar to the given transcript (include html tags) in the output.\n",
    "\n",
    "{text_summaries}\n",
    "\n",
    "{table_summaries}\n",
    "\n",
    "{image_summaries}\n",
    "\n",
    "{specific_questions}\n",
    "\n",
    "{example_transcript}\n",
    "\n",
    "Add specific questions by audience at the end of the podcast in a QA session stating something like : 'Now lets us address the questions from our Audience' \"\"\"\n",
    "\n",
    "podcast_prompt_template = PromptTemplate(template=template, input_variables=[\"text_summaries\", \"table_summaries\", \"image_summaries\", \"specific_questions\", \"example_transcript\"])\n",
    "formatted_prompt = podcast_prompt_template.format(text_summaries=text_summary, \n",
    "                                 table_summaries=table_summary, \n",
    "                                 image_summaries=image_summary,\n",
    "                                 specific_questions=specific_question_from_audience([\"What is Positional Encoding\", \"What is Attention Mechanism Formula\"]),\n",
    "                                 example_transcript=example_transcript)\n",
    "\n",
    "print(formatted_prompt)  # Output: Translate the following text to French: Hello, world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "response = model.invoke(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/transcripts/transcript.txt\", \"w\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_audio(audio_file):\n",
    "\t\"\"\"\n",
    "\tEmbeds an audio file in the notebook, making it playable.\n",
    "\n",
    "\tArgs:\n",
    "\t\taudio_file (str): Path to the audio file.\n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\tdisplay(Audio(audio_file))\n",
    "\t\tprint(f\"Audio player embedded for: {audio_file}\")\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error embedding audio: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 02:10:42,701 - podcastfy.client - INFO - Using transcript file: data/transcripts/transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating podcast...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 02:11:00,416 - podcastfy.client - INFO - Podcast generated successfully using edge TTS model\n"
     ]
    }
   ],
   "source": [
    "audio_file = generate_podcast(transcript_file='data/transcripts/transcript.txt',\n",
    "                              tts_model=\"edge\",\n",
    "                              llm_model_name=\"gpt-4o\",\n",
    "                              api_key_label=\"OPENAI_API_KEY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-rag-podcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
